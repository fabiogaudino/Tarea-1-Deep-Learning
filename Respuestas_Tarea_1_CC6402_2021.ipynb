{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Respuestas_Tarea_1_CC6402_2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCszeuRk0NuH"
      },
      "source": [
        "# Tarea 1: Activaciones y pasada hacia adelante en una red neuronal <br/> CC6204 Deep Learning, Universidad de Chile  <br/> Hoja de respuestas\n",
        "## Nombre: Fabio Gaudino\n",
        "Fecha de entrega: 6 de septiembre de 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QQB7jV7LMEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a13024e-bef1-48b0-8688-46d994448f07"
      },
      "source": [
        "# Este notebook está pensado para correr en CoLaboratory. \n",
        "# Lo único imprescindible por importar es torch \n",
        "import torch\n",
        "\n",
        "# Posiblemenete quieras instalar e importar ipdb para debuggear.\n",
        "# Si es así, descomenta lo siguiente\n",
        "# !pip install -q ipdb\n",
        "# import ipdb\n",
        "\n",
        "# Aqui instalamos la libreria de correccion del curso\n",
        "!pip install \"git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cc6204\n",
            "  Cloning https://github.com/dccuchile/CC6204.git (to revision master) to /tmp/pip-install-a3jckpsn/cc6204_02773517e2dd47c48efff581e5597065\n",
            "  Running command git clone -q https://github.com/dccuchile/CC6204.git /tmp/pip-install-a3jckpsn/cc6204_02773517e2dd47c48efff581e5597065\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cc6204) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cc6204) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from cc6204) (1.9.0+cu102)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cc6204) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cc6204) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cc6204) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cc6204) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->cc6204) (3.7.4.3)\n",
            "Building wheels for collected packages: cc6204\n",
            "  Building wheel for cc6204 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cc6204: filename=cc6204-0.5.0-py3-none-any.whl size=5800 sha256=275d6e96d0724fa8ac63633594695593c1a9b3ef0d41c5aeb74423aabb6c43ea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9tbjildd/wheels/3c/26/f5/2abeb546c3ff1ab6e69113a3ae69bc0ac3442642727fd0dcc2\n",
            "Successfully built cc6204\n",
            "Installing collected packages: cc6204\n",
            "Successfully installed cc6204-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49OevYJkMdgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07f9f3c-e7da-4f55-f3f9-47959386bbc5"
      },
      "source": [
        "# importamos las herramientas del curso\n",
        "from cc6204 import AutoCorrect, FailedTest\n",
        "\n",
        "# ingresa el host y port que posteamos en u-cursos\n",
        "\n",
        "corrector = AutoCorrect(host='cc6204.dcc.uchile.cl', port=443)\n",
        "\n",
        "# anota el token que te daremos en u-cursos\n",
        "\n",
        "token = ']ye/Ox;nsz'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection stablished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq9u0IfT0VRp"
      },
      "source": [
        "# Parte 1: Funciones de activación y función de salida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMw80P8o0qrJ"
      },
      "source": [
        "## 1a) Funciones de activación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDhcNbNT0YNr"
      },
      "source": [
        "def sig(T):\n",
        "  if type(T)==list:\n",
        "    T=torch.tensor(T)\n",
        "  return torch.reciprocal(1 + torch.exp(-1 * T))\n",
        "\n",
        "def tanh(T):\n",
        "  if type(T)==list:\n",
        "    T=torch.tensor(T)\n",
        "  E = torch.exp(T)\n",
        "  e = torch.exp(-1 * T)\n",
        "  return (E - e) * torch.reciprocal(E + e)\n",
        "\n",
        "# Tu código acá\n",
        "def relu(T):\n",
        "  if type(T)==list:\n",
        "    T=torch.tensor(T)\n",
        "  zero=torch.zeros(T.size())\n",
        "  return torch.maximum(T, zero)\n",
        "\n",
        "def swish(T, beta=1): \n",
        "  if type(T)==list:\n",
        "    T=torch.tensor(T)\n",
        "  return T*sig(beta*T)\n",
        "\n",
        "def celu(T, alpha=1):\n",
        "  if type(T)==list:\n",
        "    T=torch.tensor(T)\n",
        "  x1=relu(T)\n",
        "  x2=alpha*(torch.exp(T*(1/alpha))-1)\n",
        "  zero2=torch.zeros(x2.size())\n",
        "  x2=torch.minimum(x2, zero2)\n",
        "  return x1+x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0SmO2x7M1pn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fa7a5d-12eb-4bad-b445-0befe69e7548"
      },
      "source": [
        "# Tests del API del curso\n",
        "test_relu = corrector.get_test_data(homework=1, question=\"1a\", test=1, token=token)\n",
        "test_swish, swish_par = corrector.get_test_data(homework=1, question=\"1a\", test=2, token=token)\n",
        "test_celu, celu_par = corrector.get_test_data(homework=1, question=\"1a\", test=3, token=token)\n",
        "# probablemente quieras convertr los variables test_* a un tensor, ya que por defecto son listas\n",
        "\n",
        "corrector.submit(homework=1, question=\"1a\", test=1, token=token, answer=relu(test_relu))\n",
        "corrector.submit(homework=1, question=\"1a\", test=2, token=token, answer=swish(test_swish, swish_par))\n",
        "corrector.submit(homework=1, question=\"1a\", test=3, token=token, answer=celu(test_celu, celu_par))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Test!\n",
            "Correct Test!\n",
            "Correct Test!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_0dTh7l1bas"
      },
      "source": [
        "## 1b) Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjIyp2nL1le5"
      },
      "source": [
        "Demostración: \n",
        "\n",
        "Para la secuencia $(x_1,\\ldots,x_n)$  el resultado de $\\text{softmax}(x_1,\\ldots,x_n)$ es otra secuencia $(s_1,\\ldots,s_n)$ que cumple con:\n",
        "\n",
        "\\begin{equation}\n",
        "s_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n}e^{x_j}}\n",
        "\\end{equation}\n",
        "\n",
        "Si le restamos un valor M a todos los elementos de la secuencia $(x_1,\\ldots,x_n)$ nos queda $(x_1-M,\\ldots,x_n-M)$. Luego evaluando estos elementos en la función softmax nos queda:\n",
        "\\begin{equation}\n",
        "s_i* = \\frac{e^{x_i-M}}{\\sum_{j=1}^{n}e^{x_j-M}}=\\frac{e^{x_i}e^{-M}}{\\sum_{j=1}^{n}e^{x_j}e^{-M}} = \\frac{e^{x_i}e^{-M}}{e^{-M}\\sum_{j=1}^{n}e^{x_j}} = \\frac{e^{x_i}}{\\sum_{j=1}^{n}e^{x_j}} = s_i\n",
        "\\end{equation}\n",
        "\n",
        "Como esto se cumple $ \\forall i \\in \\{1,\\ldots, n \\}$, concluimos que $\\text{softmax}(x_1-M,\\ldots,x_n-M)=\\text{softmax}(x_1,\\ldots,x_n)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDg2sU7D1dIY"
      },
      "source": [
        "# Tu código acá\n",
        "\n",
        "def softmax(T, dim=1, estable=True):\n",
        "  if type(T)==list:\n",
        "    T=torch.tensor(T)\n",
        "  if estable:\n",
        "    T=T-torch.amax(T, dim, keepdim=True)\n",
        "  expT=torch.exp(T)\n",
        "  sumT=torch.sum(expT, dim, keepdim=True)\n",
        "  return expT * torch.reciprocal(sumT)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nJhjuGZXgkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af91d7cc-275d-4df7-898b-e6b47801432d"
      },
      "source": [
        "# Tests del API del curso\n",
        "test_softmax, _dim = corrector.get_test_data(homework=1, question=\"1b\", test=1, token=token)\n",
        "corrector.sumbit(homework=1, question=\"1b\", test=1, token=token, answer=softmax(test_softmax, dim=_dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Old method `sumbit` has been renamed to `submit`, please use that instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Test!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "662XLsDA9XXI"
      },
      "source": [
        "# Parte 2: Red neuronal y pasada hacia adelante (forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTUm9ZbX9bRA"
      },
      "source": [
        "## 2a) Clase para red neuronal, 2b) Iterando por parametros, 2d) Pasada hacia adelante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_jeuYbv9WhK"
      },
      "source": [
        "# Tu código debiera continuar así \n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C):\n",
        "    #Verificamos que las variables sean validas:\n",
        "\n",
        "    #F:\n",
        "    assert type(F)==int, \"F debe ser una número entero\"\n",
        "\n",
        "    #l_h:\n",
        "    assert type(l_h)==list, \"l_h debe ser una lista\"\n",
        "\n",
        "    #l_a:\n",
        "    assert type(l_a)==list, \"l_a debe ser una lista\"\n",
        "    for funcion in l_a:\n",
        "      assert funcion in [sig, tanh, relu, swish, celu], \"La función de activación \"+str(funcion)+\" no es valida\"\n",
        "\n",
        "    #C:\n",
        "    assert type(C)==int and C>1, \"C debe ser un numero entero mayor o igual a 2\"\n",
        "    \n",
        "    #Definimos los parámetros de la clase:\n",
        "\n",
        "    super(FFNN, self).__init__()\n",
        "\n",
        "    #Funciones de activación\n",
        "    self.funciones_de_activacion = l_a\n",
        "\n",
        "    #W_1\n",
        "    self.entrada = torch.nn.Parameter(torch.rand(F,l_h[0]))\n",
        "\n",
        "    #b_1:\n",
        "    self.entrada_sesgo = torch.nn.Parameter(torch.zeros(1,l_h[0]))\n",
        "\n",
        "    #W_i, con i perteneciente a {2,...,L}; con L número de capas escondidas\n",
        "    self.capas_escondidas = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(l_h[k], l_h[k+1])) for k in range(len(l_h)-1)]) \n",
        "\n",
        "    #b_i, con i perteneciente a {2,...,L}; con L número de capas escondidas\n",
        "    self.capas_escondidas_sesgo = torch.nn.ParameterList([torch.nn.Parameter(torch.zeros(1, l_h[k+1])) for k in range(len(l_h)-1)])\n",
        "\n",
        "    #U\n",
        "    self.salida = torch.nn.Parameter(torch.rand(l_h[len(l_h)-1],C))\n",
        "\n",
        "    #c (sesgo):\n",
        "\n",
        "    self.salida_sesgo = torch.nn.Parameter(torch.zeros(1,C))\n",
        "  \n",
        "  def resumen(self):\n",
        "    # usa self.parameters() o self.named_parameters()\n",
        "    print(\"Resumen parámetros:\")\n",
        "    for nombre, parametros in FFNN.named_parameters(self):\n",
        "      print('')\n",
        "      print(nombre)\n",
        "      print('dimensiones: '+str(parametros.size()))\n",
        "      print('')\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # Usa los parámetros y funciones de activación.\n",
        "    # El valor de retorno debiera ser y = softmax(capa_de_salida).\n",
        "\n",
        "    #Capa de entrada:\n",
        "    h = self.funciones_de_activacion[0](x.mm(self.entrada) + self.entrada_sesgo)\n",
        "\n",
        "    #Capas ocultas:\n",
        "    numero_capas_escondidas=len(self.capas_escondidas)\n",
        "    for k in range(numero_capas_escondidas): \n",
        "      h = self.funciones_de_activacion[k+1](h.mm(self.capas_escondidas[k]) + self.capas_escondidas_sesgo[k])\n",
        "\n",
        "    #Capa de salida:   \n",
        "    h = h.mm(self.salida) + self.salida_sesgo \n",
        "    y = softmax(h,1)  \n",
        "    return y \n",
        "\n",
        "  def set_pesos(self, U, W1, W2, b1, b2, c):\n",
        "    self.entrada = torch.nn.Parameter(W1)\n",
        "    self.entrada_sesgo = torch.nn.Parameter(b1)\n",
        "    self.capas_escondidas = torch.nn.ParameterList([torch.nn.Parameter(W2)])\n",
        "    self.capas_escondidas_sesgo = torch.nn.ParameterList([torch.nn.Parameter(b2)])\n",
        "    self.salida = torch.nn.Parameter(U)\n",
        "    self.salida_sesgo = torch.nn.Parameter(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgf5Xx-34Pa1"
      },
      "source": [
        "## 2c) Moviendo los parámetros entre dispositivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zppplXd4QXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3d4704-94db-4ac3-ad24-f7fb10f99f68"
      },
      "source": [
        "# Tu código acá\n",
        "red_neuronal= FFNN(9999,[100,200,300],[relu, relu, relu],100) \n",
        "red_neuronal.to('cuda')\n",
        "!nvidia-smi\n",
        "!free -h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 25 00:49:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    58W / 149W |    468MiB / 11441MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        1.8G        7.4G        4.2M        3.4G         10G\n",
            "Swap:            0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTnKxznL6Ep"
      },
      "source": [
        "# Parte 3: Probando tu red con parámetros pre-entrenados para MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOBcElJ7BPcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a6a4f9-b08f-46a1-b3bf-46a76762ba68"
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Importamos funcionalidades útiles para mirar los datos.\n",
        "from matplotlib.pyplot import subplots\n",
        "import random\n",
        "\n",
        "# Descarga y almacena el conjunto de prueba de MNIST.\n",
        "dataset = MNIST('mnist', train=False, transform=ToTensor(), download=True)\n",
        "print('Cantidad total de datos:',len(dataset))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad total de datos: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6s-z1DNL-J0"
      },
      "source": [
        "## 3b) Cargando los parámetros pre-entrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcEOXUCsPtmx"
      },
      "source": [
        "%%bash\n",
        "# Este comando es util para descargar los datos\n",
        "wget \\\n",
        "    --quiet \\\n",
        "    --no-clobber \\\n",
        "    --base https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea1/mnist_weights/ \\\n",
        "    --input-file - \\\n",
        "<<EOF\n",
        "U.txt\n",
        "W1.txt\n",
        "W2.txt\n",
        "b1.txt\n",
        "b2.txt\n",
        "c.txt\n",
        "EOF\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLeq3y8FE3SU"
      },
      "source": [
        "#Importamos loadtxt para cargar los archivos .txt\n",
        "from numpy import loadtxt\n",
        "\n",
        "#Cargamos los parámetros .txt\n",
        "U = torch.from_numpy(loadtxt('/content/U.txt')).float()\n",
        "W1 = torch.from_numpy(loadtxt('/content/W1.txt')).float()\n",
        "W2 = torch.from_numpy(loadtxt('/content/W2.txt')).float()\n",
        "b1 = torch.from_numpy(loadtxt('/content/b1.txt')).float()\n",
        "b2 = torch.from_numpy(loadtxt('/content/b2.txt')).float()\n",
        "c = torch.from_numpy(loadtxt('/content/c.txt')).float()\n",
        "\n",
        "#Definimos la red neuronal\n",
        "nn1 = FFNN(784,[32,16],[relu,relu],10)\n",
        "\n",
        "#Inicializamos los parámetros\n",
        "nn1.set_pesos(U,W1,W2,b1,b2,c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWRa68ZFMIyr"
      },
      "source": [
        "## 3c) Calcula la predicción de un ejemplo al azar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-SaIzRoMMoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "89fa5e82-974a-4d4d-9be6-8590040ecc80"
      },
      "source": [
        "# Tu código acá\n",
        "n_ejemplos=2\n",
        "fig, axs = subplots(nrows=2, figsize=(2,n_ejemplos*3))\n",
        "indice_img=[56, 99]\n",
        "for i in range(n_ejemplos):\n",
        "  T , l = dataset[indice_img[i]]\n",
        "  img = T.view(28,28).numpy()\n",
        "  axs[i].set_title(\"clase: \"+ str(l))\n",
        "  axs[i].imshow(img)\n",
        "  Prediccion = nn1.forward(T.view(1,784))\n",
        "  print('Predicción imagen '+ str(i+1)+ ': '+str(torch.argmax(Prediccion)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicción imagen 1: tensor(4)\n",
            "Predicción imagen 2: tensor(9)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1cZFU8rMNr1"
      },
      "source": [
        "## 3d) Pasando todos los ejemplos por la red con un `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL49_0ZAMRd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2537c5b5-d489-4d00-bf56-cc5aa1bf59de"
      },
      "source": [
        "# Acá tu código\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def calcula_acierto(red_neuronal, dataset, batch_size=100, device='cpu'):\n",
        "    red_neuronal.to('cpu')\n",
        "    dataloader = DataLoader(dataset, batch_size) #Cargamos los datos\n",
        "    aciertos_totales = torch.tensor([0]).cpu() \n",
        "    for x,y in dataloader: \n",
        "      x = x.view(batch_size,28*28).cpu() \n",
        "      clasificacion = red_neuronal.forward(x) \n",
        "      prediccion = torch.max(clasificacion,1)[1].cpu() \n",
        "      aciertos = torch.eq(prediccion,y.cpu()).sum().cpu() \n",
        "      aciertos_totales = aciertos_totales + aciertos \n",
        "\n",
        "    aciertos_totales  = aciertos_totales.cpu().tolist()[0] \n",
        "    return aciertos_totales/10000 * 100\n",
        "\n",
        "\n",
        "nn1 = FFNN(784,[32,16],[relu,relu],10) #Creamos la red_neuronal\n",
        "nn1.set_pesos(U,W1,W2,b1,b2,c) #Incorporamos los pesos entrenados \n",
        "\n",
        "tiempo_inicial = time.clock()  \n",
        "valor = calcula_acierto(nn1,dataset,100,'cpu')  \n",
        "tiempo = time.clock() - tiempo_inicial\n",
        "\n",
        "print('')\n",
        "print('Porcentaje de aciertos: '+str(valor)+ \"% \" + \", tiempo total: \" + str(tiempo))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Porcentaje de aciertos: 96.12% , tiempo total: 1.222409999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aKeQqw_c36O"
      },
      "source": [
        "Falto ver el caso en que la red neuronal trabaja con la gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKXqo4FpX2Id"
      },
      "source": [
        "### Corrección red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMcid2LRXzrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2efac507-9ef2-4c0a-d424-5c5c738baf6c"
      },
      "source": [
        "# Tests del API del curso\n",
        "from torch.utils.data import Subset\n",
        "indices = corrector.get_test_data(homework=1, question=\"network\", test=1, token=token)\n",
        "test_set = Subset(dataset, indices)\n",
        "\n",
        "# Modelo con los parámetros pre-entrenados para MNIST\n",
        "your_network = nn1\n",
        "\n",
        "# Montar el `test_set` en un tensor de (N, 28*28) usando DataLoader\n",
        "X = list(DataLoader(test_set, batch_size=len(test_set)))[0][0].view(-1, 28*28)\n",
        "\n",
        "# Almacenar el resultado en un puro tensor de (N,1)\n",
        "result = torch.argmax(your_network.forward(X), dim=1)\n",
        "\n",
        "corrector.submit(homework=1, question=\"network\", test=1, token=token, answer=result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cached test data\n",
            "Correct Test!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pgWygWCMYTx"
      },
      "source": [
        "## 3e) Opcional: Muestra los casos en donde la red se equivoca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM_eP23XMaTn"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beF870pABHKe"
      },
      "source": [
        "## 3d) Opcional: Crea tus propios ejemplos de dígitos para clasificar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOqCJx4LBG1W"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}